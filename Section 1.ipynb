{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Working with TensorFlow\n",
    "## Video 1: The approach of this course\n",
    "In the previous course, learning neural networks with TensorFlow, we learned about perceptrons, feed forward networks, and convolutional neural networks. We solved several classification and regression problems. \n",
    "\n",
    "However, there are a lot of different problems in this world that you can approach with neural networks. In this course we are going to take a look at several of them: \n",
    "- Autoencoders: the unsupervised learning of the representation of your data. You can also use these models to generate new data!\n",
    "- Siamese neural networks: what if you have a classification problem, but you only have several (or even only one) sample per class?\n",
    "- Reinforcement learning: what if you want to build an AI that can play a game? We are going to create an autonomous agent that trains itself!\n",
    "\n",
    "After this course you will have a better understanding of how you can use TensorFlow and neural networks to solve different types of problems!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video 2: Installing Docker, and downloading the data\n",
    "Often when you follow a course online you need to install many programs before you can finally start programming your coursework. For this course you only need to install one program: **Docker**.\n",
    "\n",
    "Docker is a tool which allows you to run an isolated operating system on your computer. It's like you are running a pc, on your pc. You can run a second Windows in Windows, or an Ubuntu (Linux) server under Windows.\n",
    "\n",
    "For this course I made a Docker image that contains all dependencys you normally would have to install. This means everyone who joins has the same Python version, the same version of Tensorflow, and no problems with libraries.\n",
    "Unfortunately, you still need to get one program running before you can start: Docker itself.\n",
    "\n",
    "### Installation\n",
    "The best way to install Docker is by looking at this webpage: https://docs.docker.com/engine/installation/#supported-platforms If you are on Windows 7 you need to install Docker Toolbox.\n",
    "This video by Elton Stoneman is a great tutorial on how to install Docker on Windows: https://www.youtube.com/watch?v=S7NVloq0EBc. \n",
    "\n",
    "For fellow OSX users I took the following screenshots to see what links you have to follow to install Docker.\n",
    "find desktopclick stabledrag docker\n",
    "Make sure you launch Docker and it runs as process in the background.\n",
    "\n",
    "### Our code, in a Jupyter notebook\n",
    "Once you install Docker getting started is easy. Open a terminal and verify that typing docker works:\n",
    "docker\n",
    "Download the code from TODO PACKT URL HERE! In the folder you downloaded create a folder called \"datasets\". We will fill this folder during the course\n",
    "\n",
    "In your terminal navigate to the folder you downloaded from Packt (using the cd command). Run the following command:\n",
    "> docker-compose build\n",
    "\n",
    "This command will take a while, as you download an image with an operating system, Tensorflow, and several libraries you need for the course. Although it might be a little bit of a hassle now I found that working with Docker for courses like this significantly improves the experience of people who can follow the course. Installing just one program turns out to be way better than installing the 5 libraries you need during the course.\n",
    "\n",
    "Once this command is done you run the following command:\n",
    "> docker-compose up\n",
    "\n",
    "If all went well you should be able to navigate to localhost:8888 and see the following screen:\n",
    "\n",
    "starting point\n",
    "\n",
    "Click on \"Section 1 Introduction to Docker, Tensorflow, and Jupyter Notebooks.ipynb\" and you should jump right into this notebook!\n",
    "\n",
    "What is a Jupyter Notebook?\n",
    "A Jupyter Notebook is an interactive computing environment in which I will type all explanations, put useful links in, and will put code in, like this:\n",
    "\n",
    "\n",
    "What's nice about a Jypter Notebook is that between code I can give a bit of explanation. This way, if you go through the notebook later, you don't have to find the relevant part of the video again.\n",
    "Inside a Jypyter notebook you can draw graphs with Matplotlib. To do this you do have to use a \"magic\" command:\n",
    "\n",
    "Note that you can even execute parts of the notebook again, the notebook keeps track of its Python kernel. Hopefully you like the use of a Jupyter notebook. I personally love it so much that I always use it when exploring how I can solve a dataset!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video 3: Quick example of how to use a Jupyter notebook, and datasets that might be interesting for this course - Explore your Jupiter Notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully you followed the first course on TensorFlow that I gave. If you did you can use this section to refresh your memory on how we work with TensorFlow. \n",
    "\n",
    "If you did not follow my course take a little longer to look at the code I use. I really like the `tf.layers` part of TensorFlow and make extensive use of it. Make sure you understand what I do below before moving on to the more advanced parts of the course. \n",
    "\n",
    "### Downloading data\n",
    "A function that downloads the MNIST data is included in TensorFlow. During this course we always download our datasets in the datasets folder. If you run this part of the code for the first time it can take a while as it has to download and unzip all the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting datasets/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting datasets/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting datasets/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting datasets/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "784\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt \n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "logging_dir_n = 0 \n",
    "\n",
    "mnist = input_data.read_data_sets('datasets/MNIST_data', one_hot=True)\n",
    "input_dim = mnist.train.images[0].shape[0]\n",
    "h_image=28\n",
    "w_image=28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding layers to our neural network\n",
    "The simplest way of building a neural network is using the `tf.layers` part of TensorFlow. With these functions you specify what tensors come into the layer, and what kind of output you would like to see. A simple neural network would look like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_units = 512\n",
    "\n",
    "input_placeholder = tf.placeholder(dtype=tf.float32, shape=[None, input_dim], name='inputplaceholder')\n",
    "output_placeholder = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "dense1 = tf.layers.dense(input_placeholder, hidden_units, activation = tf.nn.relu)\n",
    "predicted = tf.layers.dense(dense1, 10, activation = tf.nn.sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that to train a network you have to define a loss function and an optimizer. Let's go for the simplest one we know: the mean squared error. Let's also use the simplest optimizer we know: gradient descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.losses.mean_squared_error(output_placeholder, predicted)\n",
    "learning_rate = 0.05\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you can train you have to create a session, and initialize all variables. After that you can train your network. The sess.run function needs two arguments: what we want to get out of our graph, and what we feed into the graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_size = 128\n",
    "num_iterations = 2000\n",
    "\n",
    "loss_history = list()\n",
    "for i in range(num_iterations):\n",
    "    batch = mnist.train.next_batch(batch_size)\n",
    "\n",
    "    _, l = sess.run([optimizer, loss], feed_dict={input_placeholder: batch[0], output_placeholder: batch[1]})\n",
    "    loss_history.append(l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cool thing of our Jupyter notebook is that we can plot data and results using Matplotlib. The results will appear \"inline\" as we defined that at the top of our notebook: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f001c0b80b8>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f001e98ca90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a convolutional neural network\n",
    "Although we see that our network is learning something, we can improve our network by using [convolutional layers](https://en.wikipedia.org/wiki/Convolutional_neural_network). To recap: we can add these layers to our network using TensorFlow's `tf.layers.conv2d` and `tf.layers.max_pooling2d` functions. \n",
    "\n",
    "Remember that there are several loss functions, and several optimization algorithms. As we learned that softmax cross entropy is a good loss measure for classification problems we will use that one here. We also know that the Adam optimizer often gives a great performance while we don't have to tweak any learning rate parameters. For this reason we will often encounter this optimizer during this course. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flattened' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-45ad659ae981>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmaxp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pooling2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maxp2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mflatted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflattened\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'flattened' is not defined"
     ]
    }
   ],
   "source": [
    "input_reshaped = tf.reshape(input_placeholder, [-1, h_image, w_image, 1])\n",
    "conv1 = tf.layers.conv2d(input_reshaped, 8, [5, 5], name='conv1', activation=tf.nn.relu)\n",
    "maxp1 = tf.layers.max_pooling2d(conv1, (2,2),(2,2), name='maxp1')\n",
    "conv2 = tf.layers.conv2d(maxp1, 32, [3, 3], name='conv2', activation=tf.nn.relu)\n",
    "maxp2 = tf.layers.max_pooling2d(conv2, (2,2), (2,2), name=\"maxp2\")\n",
    "flattened = tf.contrib.layers.flatten(maxp2)\n",
    "print(flattened)\n",
    "\n",
    "flat1 = tf.layers.dense(flattened, 256, activation=tf.nn.relu, name=\"dense1\")\n",
    "predicted = tf.layers.dense(flat2, 10, name=\"dense2\")\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=output_placeholder, logits=predicted))\n",
    "\n",
    "## ADAM OPTIMIZER\n",
    "trainstep = tf.train.AdamOptimizer().minimize(cross_entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Flatten/Reshape:0\", shape=(?, 800), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_size = 128\n",
    "num_iterations = 500\n",
    "\n",
    "loss_history = list()\n",
    "for i in range(num_iterations):\n",
    "    batch = mnist.train.next_batch(batch_size)\n",
    "\n",
    "    _, l = sess.run([trainstep, cross_entropy], feed_dict={input_placeholder: batch[0], output_placeholder: batch[1]})\n",
    "    loss_history.append(l)\n",
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "We went through this Jupyter notebook together, and recapped how TensorFlow works by building a simple neural network that can recognize written characters. In the next section we will discuss what TensorBoard is, and how you can use it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
