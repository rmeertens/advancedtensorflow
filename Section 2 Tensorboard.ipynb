{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: TensorBoard\n",
    "Included in the TensorFlow installation is a tool called TensorBoard. With this tool you can visualise everything coming into your neural network and leaving your neural network. In this section I will demonstrate how you can use it. In later sections we will continue to use it to monitor our neural network (training) using TensorBoard. \n",
    "\n",
    "## Video 1: starting TensorBoard and visualising a graph\n",
    "Let's say you are developing a deep neural network that can recognize characters. We take the classic MNIST dataset and quickly build a neural network using `tf.layers`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting datasets/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting datasets/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting datasets/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting datasets/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt \n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('datasets/MNIST_data', one_hot=True)\n",
    "input_dim = mnist.train.images[0].shape[0]\n",
    "output_dim = 10\n",
    "h_image=28\n",
    "w_image=28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Flatten/Reshape:0\", shape=(?, 288), dtype=float32)\n",
      "INFO:tensorflow:logits.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:multi_class_labels.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:losses.dtype=<dtype: 'float32'>.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "## INPUT AND OUTPUT PLACEHOLDER\n",
    "input_placeholder = tf.placeholder(dtype=tf.float32, shape=[None, input_dim], name='inputplaceholder')\n",
    "output_placeholder = tf.placeholder(dtype=tf.float32, shape=[None, output_dim], name='outputplaceholder')\n",
    "\n",
    "reshaped_input = tf.reshape(input_placeholder, [-1, h_image, w_image, 1])\n",
    "conv1 = tf.layers.conv2d(reshaped_input, 32, [3,3], activation=tf.nn.relu, name=\"conv1\")\n",
    "conv1_mp = tf.layers.max_pooling2d(conv1, [2,2], [2,2])\n",
    "conv2 = tf.layers.conv2d(conv1_mp, 32, [3,3], activation=tf.nn.relu, name=\"conv2\")\n",
    "conv2_mp = tf.layers.max_pooling2d(conv2, [2,2], [2,2])\n",
    "conv3 = tf.layers.conv2d(conv2_mp, 32, [3,3], activation=tf.nn.relu, name=\"conv3\")\n",
    "flattened = tf.contrib.layers.flatten(conv3)\n",
    "\n",
    "print(flattened)\n",
    "output = tf.layers.dense(flattened, output_dim, activation=None)\n",
    "loss = tf.losses.sigmoid_cross_entropy(output_placeholder, output)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5b50dd5ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "iterations = 1000\n",
    "batch_size = 128\n",
    "loss_history = list()\n",
    "for iteration in range(iterations):\n",
    "    batch = mnist.train.next_batch(batch_size)\n",
    "    _, l = sess.run([optimizer, loss],\n",
    "                                feed_dict={input_placeholder: batch[0], output_placeholder: batch[1]})\n",
    "    loss_history.append(l)\n",
    "\n",
    "plt.plot(loss_history[20:])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Tensorboard?\n",
    "By now you probably noticed that building a model and training a neural network can be a lot of fidgeting with hyper parameters and layers. Sometimes it can be difficult to see the performance between two models, and debugging models is often difficult. A tool that really helps you with this is Tensorboard: a web application that reads event files you can write away with TensorFlow. \n",
    "\n",
    "\n",
    "### Starting Tensorboard\n",
    "When you ran `docker-compose up` you not only started a virtual operating system with Tensorflow and Jupyter notebook, but also started a server that runs Tensorboard. Tensorboard is now accessible by navigating to `localhost:6006`. As we did not use it yet, you will probably see the following screen: \n",
    "\n",
    "![tensorempty](illustrations/section2/tensorboardempty.png)\n",
    "\n",
    "This is because we did not write anything yet. \n",
    "\n",
    "### Writing your graph\n",
    "\n",
    "To write your graph (and any other data) you have to initialize a Filewrite object. The constructor requires you to give the name of the directory you want to log in, and the graph you want to use for this writer. \n",
    "\n",
    "During this course we write everything to the graphs directory (as Tensorboard looks in this directory). Apart from the we make a directory per section during this course. After you did this there is one more thing remaining: it is good practice to put each model you make (every time you change something you have a new model) in a separate folder. You will see later why this is useful. Now let's start by starting a FileWriter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter(logdir='graphs/tensorboardexplanation/firstwriter' , graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wait a while, or refresh the Tensorboard page, you should be able to navigate to the Graphs tab, and visualise your graph:\n",
    "![tensorempty](illustrations/section2/foundrun.png)\n",
    "\n",
    "Note: sometimes you have to refresh Tensorboard before he finds your graph definition... \n",
    "\n",
    "![tensorempty](illustrations/section2/firstgraphvis.png)\n",
    "\n",
    "The gradients block makes everything a bit difficult to inspect, so you can remove this by clicking on the gradients with your right mouse button. \n",
    "\n",
    "![tensorempty](illustrations/section2/removefromgraph.png)\n",
    "\n",
    "This should give your the following graph: \n",
    "\n",
    "![tensorempty](illustrations/section2/nicegraph.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video 2: Adding summaries\n",
    "\n",
    "Now that we are able to get our graph in Tensorboard it's time to add something more interesting: the loss. Right now we are working with Matplotlib, and either have to store the losses somewhere, or have to figure out what model works better...\n",
    "\n",
    "With Tensorboard we can simply improve on this by using multiple logging directories. Especially with a Jupyter Notebook doing this is easy. Here is my normal working routing when trying to build a good neural network: \n",
    "- Determine in what directory I will log, set a variable to zero\n",
    "- Build a (simple) initial graph\n",
    "- Write things to a directory (and increment variable by one for next time)\n",
    "- Adjust network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the first step, and set a variable to zero and make a directory: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging_dir_n = 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actually logging something\n",
    "So far we did not log anything, we can do so by adding a scalar summary of the loss value. Note that instead of the next block I do this in the block after that: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:logits.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:multi_class_labels.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:losses.dtype=<dtype: 'float32'>.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "input_placeholder = tf.placeholder(dtype=tf.float32, shape=[None, input_dim], name='inputplaceholder')\n",
    "output_placeholder = tf.placeholder(dtype=tf.float32, shape=[None, output_dim], name='outputplaceholder')\n",
    "\n",
    "reshaped_input = tf.reshape(input_placeholder, [-1, h_image, w_image, 1])\n",
    "conv1 = tf.layers.conv2d(reshaped_input, 32, [3,3], activation=tf.nn.relu, name=\"conv1\")\n",
    "conv1_mp = tf.layers.max_pooling2d(conv1, [2,2], [2,2])\n",
    "conv2 = tf.layers.conv2d(conv1_mp, 32, [3,3], activation=tf.nn.relu, name=\"conv2\")\n",
    "conv2_mp = tf.layers.max_pooling2d(conv2, [2,2], [2,2])\n",
    "conv3 = tf.layers.conv2d(conv2_mp, 32, [3,3], activation=tf.nn.relu, name=\"conv3\")\n",
    "\n",
    "flattened = tf.contrib.layers.flatten(conv3)\n",
    "output = tf.layers.dense(flattened, output_dim, activation=None)\n",
    "\n",
    "loss = tf.losses.sigmoid_cross_entropy(output_placeholder, output)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_summary = tf.summary.scalar('loss', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "writer = tf.summary.FileWriter(logdir='graphs/tensorboardexplanation/tutorial/'+str(logging_dir_n) , graph=tf.get_default_graph())\n",
    "logging_dir_n += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing to the summary\n",
    "Instead of asking the graph to give me the loss each iteration I now ask the graph to give me the summary of the loss. I collect all summaries and add them to my writer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for iteration in range(iterations):\n",
    "    batch = mnist.train.next_batch(batch_size)\n",
    "    _, summary = sess.run([optimizer, loss_summary],\n",
    "                                feed_dict={input_placeholder: batch[0], output_placeholder: batch[1]})\n",
    "    writer.add_summary(summary, iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting your graph\n",
    "Now that we have a first loss we can adjust our graph, and see if the loss improves (or becomes worse...). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "writer = tf.summary.FileWriter(logdir='graphs/tensorboardexplanation/tutorial/'+str(logging_dir_n) , graph=tf.get_default_graph())\n",
    "logging_dir_n += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for iteration in range(iterations):\n",
    "    batch = mnist.train.next_batch(batch_size)\n",
    "    _, summary = sess.run([optimizer, loss_summary],\n",
    "                                feed_dict={input_placeholder: batch[0], output_placeholder: batch[1]})\n",
    "    writer.add_summary(summary, iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "You can now see the difference between two optimizers, all in one graph! Although you can easily see the difference in quality between two layouts, you can now easily change part of the graph, train, and see the difference with your previous results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video 3: inspecting weights\n",
    "\n",
    "Let's say that you totally misinterpreted the learning rate: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.losses.mean_squared_error(output_placeholder, output)\n",
    "optimizer = tf.train.GradientDescentOptimizer(4.5).minimize(loss)\n",
    "iterations = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.124975\n",
      "0.391151\n",
      "0.410753\n",
      "32.1005\n",
      "24.8317\n",
      "5.39569\n",
      "11.9054\n",
      "0.465106\n",
      "0.0937922\n",
      "0.0897405\n",
      "0.0914311\n",
      "0.0904819\n",
      "0.0908581\n",
      "0.0903916\n",
      "0.0902783\n",
      "0.0908097\n",
      "0.0897422\n",
      "0.0903243\n",
      "0.0912863\n",
      "0.0902907\n",
      "0.0906799\n",
      "0.0910673\n",
      "0.090572\n",
      "0.0913428\n",
      "0.0910211\n",
      "0.0902002\n",
      "0.0897306\n",
      "0.0906953\n",
      "0.0900082\n",
      "0.0899592\n",
      "0.0918764\n",
      "0.090437\n",
      "0.0901751\n",
      "0.0902231\n",
      "0.0901788\n",
      "0.0911987\n",
      "0.0901641\n",
      "0.089908\n",
      "0.0914725\n",
      "0.0906947\n",
      "0.0915322\n",
      "0.0902214\n",
      "0.0913384\n",
      "0.0919104\n",
      "0.0902416\n",
      "0.0902843\n",
      "0.0910322\n",
      "0.0907589\n",
      "0.0913022\n",
      "0.0912314\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "writer = tf.summary.FileWriter(logdir='graphs/tensorboardexplanation/tutorial/'+str(logging_dir_n) , graph=tf.get_default_graph())\n",
    "logging_dir_n += 1\n",
    "\n",
    "for iteration in range(iterations):\n",
    "    batch = mnist.train.next_batch(batch_size)\n",
    "    _, l, summary = sess.run([optimizer, loss, loss_summary],\n",
    "                                feed_dict={input_placeholder: batch[0], output_placeholder: batch[1]})\n",
    "    print(l)\n",
    "    writer.add_summary(summary, iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Looking at Tensorboard you now see the loss go up, but you have no idea why. The graph looks really good (no wrong passes...), but you clearly see your loss going up. \n",
    "\n",
    "Now is a good time to either inspect your gradients, inspect activations, or inspect your weights. Let's take weights for example: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1/kernel:0\n",
      "conv1/bias:0\n",
      "conv2/kernel:0\n",
      "conv2/bias:0\n",
      "conv3/kernel:0\n",
      "conv3/bias:0\n",
      "dense/kernel:0\n",
      "dense/bias:0\n",
      "beta1_power:0\n",
      "beta2_power:0\n",
      "conv1/kernel/Adam:0\n",
      "conv1/kernel/Adam_1:0\n",
      "conv1/bias/Adam:0\n",
      "conv1/bias/Adam_1:0\n",
      "conv2/kernel/Adam:0\n",
      "conv2/kernel/Adam_1:0\n",
      "conv2/bias/Adam:0\n",
      "conv2/bias/Adam_1:0\n",
      "conv3/kernel/Adam:0\n",
      "conv3/kernel/Adam_1:0\n",
      "conv3/bias/Adam:0\n",
      "conv3/bias/Adam_1:0\n",
      "dense/kernel/Adam:0\n",
      "dense/kernel/Adam_1:0\n",
      "dense/bias/Adam:0\n",
      "dense/bias/Adam_1:0\n"
     ]
    }
   ],
   "source": [
    "## Print variable names; \n",
    "for v in tf.global_variables():\n",
    "    print(v.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visualise a histogram with the `tf.summary.histogram` function. We do this for each kernel in our graph by adding a histogram for each variable with the name \"kernel\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "histograms = []\n",
    "for v in tf.global_variables():\n",
    "    if \"kernel\" in v.name:\n",
    "        toadd = tf.summary.histogram(v.name[:-2], v)\n",
    "        histograms.append(toadd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can log these in our summary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "writer = tf.summary.FileWriter(logdir='graphs/tensorboardexplanation/tutorial/'+str(logging_dir_n) , graph=tf.get_default_graph())\n",
    "logging_dir_n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for iteration in range(iterations):\n",
    "    batch = mnist.train.next_batch(batch_size)\n",
    "    _, summary = sess.run([optimizer, loss_summary],\n",
    "                                feed_dict={input_placeholder: batch[0], output_placeholder: batch[1]})\n",
    "    writer.add_summary(summary, iteration)\n",
    "    \n",
    "    ## Log the histograms of weights and add them as a summary\n",
    "    weights_in_graph = sess.run(histograms)\n",
    "    for logged_weight in weights_in_graph: \n",
    "        writer.add_summary(logged_weight, iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing it to a \"normal\" situation\n",
    "Now let's compare this to a \"normal\" situation, where we hopefully don't see all weights explode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.losses.mean_squared_error(output_placeholder, output)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "writer = tf.summary.FileWriter(logdir='graphs/tensorboardexplanation/tutorial/'+str(logging_dir_n) , graph=tf.get_default_graph())\n",
    "logging_dir_n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for iteration in range(iterations):\n",
    "    batch = mnist.train.next_batch(batch_size)\n",
    "    _, summary = sess.run([optimizer, loss_summary],\n",
    "                                feed_dict={input_placeholder: batch[0], output_placeholder: batch[1]})\n",
    "    writer.add_summary(summary, iteration)\n",
    "    weights_in_graph = sess.run(histograms)\n",
    "    for logged_weight in weights_in_graph: \n",
    "        writer.add_summary(logged_weight, iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video 4: inspecting input/output\n",
    "You can even use TensorBoard to show your input and outputs. Use the image summary to add an image to Tensorboard. This can help you when your network is not learning anything: it might just be possible that your network is not receiving any sensible input at all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_summary = tf.summary.image('inputimage', reshaped_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "writer = tf.summary.FileWriter(logdir='graphs/tensorboardexplanation/tutorial/'+str(logging_dir_n) , graph=tf.get_default_graph())\n",
    "logging_dir_n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for iteration in range(10):\n",
    "    batch = mnist.train.next_batch(batch_size)\n",
    "    _, summary, im_sum = sess.run([optimizer, loss_summary, image_summary],\n",
    "                                feed_dict={input_placeholder: batch[0], output_placeholder: batch[1]})\n",
    "    writer.add_summary(summary, iteration)\n",
    "    writer.add_summary(im_sum, iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging summaries\n",
    "Right now we ask for each summary separately in our session. Luckily Tensorboard can improve on this by using the following function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "writer = tf.summary.FileWriter(logdir='graphs/tensorboardexplanation/tutorial/'+str(logging_dir_n) , graph=tf.get_default_graph())\n",
    "logging_dir_n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for iteration in range(iterations):\n",
    "    batch = mnist.train.next_batch(batch_size)\n",
    "    _, summary = sess.run([optimizer, merged],\n",
    "                                feed_dict={input_placeholder: batch[0], output_placeholder: batch[1]})\n",
    "    writer.add_summary(summary, iteration)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "We are now logging all summaries we defined to Tensorboard! You can define way more things you want to log, like the accuracy of your network, other loss functions, activations in different layers, whatever you want! We will use Tensorboard in the next section, so you can easily tinker with your graph and see how well it improves the performance. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
